services:
  # ugh the only solution i can come up with is a dind instance paired with every single build-bot we will need like k8s groups or something
  dind:
    expose:
      - "2375"
    profiles:
      - development
      - competition
    image: docker:24-dind
    command: ["dockerd", "-H", "tcp://0.0.0.0:2375", "--tls=false", "--storage-driver=overlay2"]
    restart: always
    privileged: true  # This must run with privlege to support nested virtualization within the public Linux CP for `virtme-ng`
    environment:
      - DOCKER_TLS_CERTDIR  # intentionally blank to optimize runtime
    volumes:
      - type: bind
        source: ./crs_scratch
        target: /crs_scratch
  redis:
    image: redis:7.4.2
    restart: always
    ports:
      - '6379:6379'
    command: redis-server /mount/redis.conf
    volumes: 
      - cache:/data
      - ./redis:/mount
    healthcheck:
      test: [ "CMD-SHELL", "redis-cli ping | grep PONG" ]
      interval: 1s
      timeout: 3s
      retries: 5
  
  stimulate-fuzzer-test:
    image: fuzzer-runnner-image
    command: -m buttercup.fuzzing_infra.stimulate_build_bot --ossfuzz /crs_scratch/ossfuzz --engine libfuzzer --sanitizer address --target_package ${TARGET_PACKAGE} --redis_url redis://redis:6379
    restart: no
    profiles:
      - development
    build:
      context: ./
      dockerfile: ./fuzzer/dockerfiles/runner_image.Dockerfile
    volumes:
      - ./crs_scratch:/crs_scratch
    depends_on:
      redis:
        condition: service_healthy
  orchestrator-sim:
    image: fuzzer-runnner-image
    command: -m buttercup.fuzzing_infra.orchestrator --redis_url redis://redis:6379
    profiles:
      - development
    build:
      context: ./
      dockerfile: ./fuzzer/dockerfiles/runner_image.Dockerfile
    volumes:
      - ./crs_scratch:/crs_scratch
    depends_on:
      redis:
        condition: service_healthy
  build-bot:
    image: fuzzer-runnner-image
    command: -m buttercup.fuzzing_infra.builder_bot --wdir /crs_scratch --redis_url redis://redis:6379
    build:
      context: ./
      dockerfile: ./fuzzer/dockerfiles/runner_image.Dockerfile
    volumes:
      - ./crs_scratch:/crs_scratch
    environment:
      # These values will be modified automatically at competition time
      - DOCKER_HOST=tcp://dind:2375
    depends_on:
      redis:
        condition: service_healthy
      dind:
        condition: service_started
  fuzzer-bot:
    image: fuzzer-runnner-image
    command: -m buttercup.fuzzing_infra.fuzzer_bot --wdir /crs_scratch --redis_url redis://redis:6379 --timeout 900
    volumes:
      - ./crs_scratch:/crs_scratch
    depends_on:
      redis:
        condition: service_healthy

  task-downloader:
    build:
      context: .
      dockerfile: ./orchestrator/Dockerfile
    command: ["buttercup-task-downloader", "serve"]
    environment:
      - BUTTERCUP_DOWNLOADER_SERVE__REDIS_URL=redis://redis:6379
      - BUTTERCUP_DOWNLOADER_LOG_LEVEL=debug

  task-server:
    build:
      context: .
      dockerfile: ./orchestrator/Dockerfile
    command: ["buttercup-task-server"]
    ports:
      - "127.0.0.1:8000:8000"
    environment:
      - BUTTERCUP_TASK_SERVER_REDIS_URL=redis://redis:6379
      - BUTTERCUP_TASK_SERVER_LOG_LEVEL=debug
      - BUTTERCUP_TASK_SERVER_HOST=0.0.0.0
      - BUTTERCUP_TASK_SERVER_PORT=8000

  litellm:
    image: ghcr.io/berriai/litellm:litellm_stable_release_branch-v1.57.8-stable
    configs:
      - source: litellm_config
        target: /app/config.yaml
    env_file: .env
    ports:
      - "127.0.0.1:8080:8080"
    environment:
        DATABASE_URL: "postgresql://litellm_user:litellm_password11@litellm-db:5432/litellm"

    command: ["--config", "/app/config.yaml", "--port", "8080"]
    depends_on:
      litellm-db:
        condition: service_healthy

  litellm-db:
    image: postgres:17.2
    restart: always
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: litellm_user
      POSTGRES_PASSWORD: litellm_password11
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 10

configs:
  litellm_config:
    file: ./litellm/litellm_config.yaml

volumes:
  cache:
    driver: local
